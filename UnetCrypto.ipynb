{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNdCMVwHgngG",
        "outputId": "c5949679-0478-402e-b98f-6d5a538122ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models\n",
        "import urllib.request\n",
        "import scipy.io as io\n",
        "import h5py\n",
        "import progressbar\n",
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import EfficientNetB5, Xception,ResNet50V2\n"
      ],
      "metadata": {
        "id": "DGkzItnVhH5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "TIME_STEP = 256\n",
        "VAL_SIZE = 0.22\n",
        "NUM_FEATURES = 10\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 64"
      ],
      "metadata": {
        "id": "HdEGOyxfBPHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_example(data, target):\n",
        "  feature = {\n",
        "      'data': _float_feature(data),\n",
        "      'target': _float_feature([target])\n",
        "  }\n",
        "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  return example_proto.SerializeToString()\n"
      ],
      "metadata": {
        "id": "U40nPcBlhNwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/drive/MyDrive/5min/BTCUSDT.csv'\n",
        "data = pd.read_csv(path_to_csv)\n",
        "data = data.drop(columns=['Close-time', 'Open-time'])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "eaJhG37t9eB8",
        "outputId": "1c8c5368-d12b-46f4-bf55-4ebca6ccdd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81bfa1a2-e396-4920-ae1a-cbea146230fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Quote-asset-volume</th>\n",
              "      <th>Number-of-trades</th>\n",
              "      <th>Taker-buy-base-asset-volume</th>\n",
              "      <th>Taker-buy-quote-asset-volume</th>\n",
              "      <th>Can-be-ignored</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4261.48</td>\n",
              "      <td>4280.56</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>2.189061</td>\n",
              "      <td>9333.620962</td>\n",
              "      <td>9</td>\n",
              "      <td>0.489061</td>\n",
              "      <td>2089.104962</td>\n",
              "      <td>7960.375295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7959.626292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7958.417415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4261.48</td>\n",
              "      <td>4264.88</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>4261.48</td>\n",
              "      <td>0.484666</td>\n",
              "      <td>2065.447829</td>\n",
              "      <td>9</td>\n",
              "      <td>0.085455</td>\n",
              "      <td>364.218136</td>\n",
              "      <td>7958.348965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4264.88</td>\n",
              "      <td>4266.29</td>\n",
              "      <td>4264.88</td>\n",
              "      <td>4266.29</td>\n",
              "      <td>2.328570</td>\n",
              "      <td>9931.161124</td>\n",
              "      <td>11</td>\n",
              "      <td>1.546491</td>\n",
              "      <td>6595.688039</td>\n",
              "      <td>7953.969349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81bfa1a2-e396-4920-ae1a-cbea146230fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81bfa1a2-e396-4920-ae1a-cbea146230fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81bfa1a2-e396-4920-ae1a-cbea146230fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Open     High  ...  Taker-buy-quote-asset-volume  Can-be-ignored\n",
              "0  4261.48  4280.56  ...                   2089.104962     7960.375295\n",
              "1  4261.48  4261.48  ...                      0.000000     7959.626292\n",
              "2  4261.48  4261.48  ...                      0.000000     7958.417415\n",
              "3  4261.48  4264.88  ...                    364.218136     7958.348965\n",
              "4  4264.88  4266.29  ...                   6595.688039     7953.969349\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUeJ-Qun_B4r",
        "outputId": "990c537f-8849-485c-c02f-defeca4a8493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(453594, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding\n",
        "if data.shape[0]%TIME_STEP!=0.0:\n",
        "  padd_data = np.zeros((TIME_STEP*(data.shape[0]//TIME_STEP+1)+1,data.shape[1]))\n",
        "  print('added {zeros} zeros'.format(zeros=padd_data.shape[0]-data.shape[0]))\n",
        "  padd_data[padd_data.shape[0]-data.shape[0]:,:] = data\n",
        "else:\n",
        "  padd_data = np.zeros((data.shape[0]+1,data.shape[1]))\n",
        "  print('added {zeros} zero'.format(zeros=1))\n",
        "  padd_data[1:,:] = data\n",
        "data = padd_data.copy()\n",
        "del padd_data\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzRjjZ5-BG-t",
        "outputId": "205ec22c-13ca-4f0b-baf2-06f0c3745582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added 1 zero\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(453633, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "453633-453376"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQXl1eXwoOz4",
        "outputId": "12a91bd0-8b47-40d5-93f4-2bd9c6f2ab17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_val = data.shape[0]- 1 - 255\n",
        "indices = np.arange(max_val)\n",
        "max(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFT9wqs7I-H7",
        "outputId": "584a5df0-d4b7-4b68-f1b5-be91b19ee5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "453376"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "453376+256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu7ujMecomxJ",
        "outputId": "0eb8e5ef-fdeb-430a-cf9b-9e218c79dc32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "453632"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_data = data[5:5+256,:]\n",
        "mx1 = np.max(sub_data, axis= 0)\n",
        "sub_data = data[9:9+256,:]\n",
        "mx2 = np.max(sub_data, axis= 0)"
      ],
      "metadata": {
        "id": "HtYl23YzvFgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mx1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2biJMt7vwOr",
        "outputId": "6fdc6c6a-2e23-440f-a98f-b376670fc39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.48539000e+03, 4.48539000e+03, 4.48539000e+03, 4.48539000e+03,\n",
              "       1.98580650e+01, 8.47179981e+04, 7.70000000e+01, 1.31385010e+01,\n",
              "       5.66677835e+04, 8.67317144e+03])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mx2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8_yBHmTvwKn",
        "outputId": "49dfd2f6-7da6-40a1-e98e-e87d88698bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.48539000e+03, 4.48539000e+03, 4.48539000e+03, 4.48539000e+03,\n",
              "       1.98580650e+01, 8.47179981e+04, 7.70000000e+01, 1.31385010e+01,\n",
              "       5.66677835e+04, 8.71576180e+03])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = mx1.copy()\n",
        "a[np.where(mx2>mx1)] = mx2[np.where(mx2>mx1)]\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZN3o51JvePe",
        "outputId": "56b7e498-86ac-487c-86a6-b2dd2cf30cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.48539000e+03, 4.48539000e+03, 4.48539000e+03, 4.48539000e+03,\n",
              "       1.98580650e+01, 8.47179981e+04, 7.70000000e+01, 1.31385010e+01,\n",
              "       5.66677835e+04, 8.71576180e+03])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tfrecs(path_to_csv ,save_path = '/content/data'):\n",
        "  name = path_to_csv.split('/')[-1]\n",
        "  name = name.split('.csv')[0]\n",
        "\n",
        "  data = pd.read_csv(path_to_csv)\n",
        "  data = data.drop(columns=['Close-time', 'Open-time'])\n",
        "  data = np.array(data)\n",
        "  # padding\n",
        "  if data.shape[0]%TIME_STEP!=0.0:\n",
        "    padd_data = np.zeros((TIME_STEP*(data.shape[0]//TIME_STEP+1)+1,data.shape[1]))\n",
        "    padd_data[padd_data.shape[0]-data.shape[0]:,:] = data\n",
        "  else:\n",
        "    padd_data = np.zeros((data.shape[0]+1,data.shape[1]))\n",
        "    padd_data[1:,:] = data\n",
        "  data = padd_data.copy()\n",
        "  del padd_data\n",
        "\n",
        "  # train val indices\n",
        "  max_idx = data.shape[0]- 1 - 255\n",
        "  indices = np.arange(max_idx)\n",
        "  train_idx, val_idx = train_test_split(indices, test_size=VAL_SIZE, random_state=40)\n",
        "  train_idx = sorted(train_idx.tolist())\n",
        "  val_idx = sorted(val_idx.tolist())\n",
        "\n",
        "  max_values = np.zeros((NUM_FEATURES,))\n",
        "  num_positives= 0\n",
        "  with tf.io.TFRecordWriter(os.path.join(save_path, name + '_train.tfrec')) as writer:\n",
        "    for i in train_idx:\n",
        "      sub_data = data[i:i+256,:]\n",
        "\n",
        "      mx1 = np.max(sub_data, axis= 0)\n",
        "      max_values[np.where(mx1>max_values)] = mx1[np.where(mx1>max_values)]\n",
        "\n",
        "      label = 0\n",
        "      if data[i+256,3]> data[i+256-1,3] :\n",
        "        label = 1\n",
        "        num_positives += 1\n",
        "\n",
        "      example = serialize_example(sub_data.reshape(-1,1), label)\n",
        "      writer.write(example)\n",
        "  print('Class 1:',num_positives )\n",
        "  num_positives = 0\n",
        "  with tf.io.TFRecordWriter(os.path.join(save_path, name + '_val.tfrec')) as writer:\n",
        "    for i in val_idx:\n",
        "      sub_data = data[i:i+256,:]\n",
        "      label = 0\n",
        "      if data[i+256,3]> data[i+256-1,3] :\n",
        "        label = 1\n",
        "        num_positives += 1\n",
        "\n",
        "      example = serialize_example(sub_data.reshape(-1,1), label)\n",
        "      writer.write(example)\n",
        "  print('Class 1:VAL:',num_positives )\n",
        "  return len(train_idx), len(val_idx), max_values"
      ],
      "metadata": {
        "id": "kwLlrA_vhNmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(2.54)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPWa7vamD2m7",
        "outputId": "d6a448bc-8d05-45f1-b464-f374d0126ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tfrecs(path_to_csv ,save_path = '/content/data'):\n",
        "  name = path_to_csv.split('/')[-1]\n",
        "  name = name.split('.csv')[0]\n",
        "\n",
        "  data = pd.read_csv(path_to_csv)\n",
        "  data = data.drop(columns=['Close-time', 'Open-time'])\n",
        "  data = np.array(data)\n",
        "  # padding\n",
        "  if data.shape[0]%TIME_STEP!=0.0:\n",
        "    padd_data = np.zeros((TIME_STEP*(data.shape[0]//TIME_STEP+1)+1,data.shape[1]))\n",
        "    padd_data[padd_data.shape[0]-data.shape[0]:,:] = data\n",
        "  else:\n",
        "    padd_data = np.zeros((data.shape[0]+1,data.shape[1]))\n",
        "    padd_data[1:,:] = data\n",
        "  data = padd_data.copy()\n",
        "  del padd_data\n",
        "\n",
        "  # train val indices\n",
        "  max_idx = data.shape[0]- 1 - 255\n",
        "  train_idx = np.arange(start=0, stop=int(0.7*max_idx))\n",
        "  train_idx = train_idx.tolist()\n",
        "  val_idx = np.arange(start=int(0.7*max_idx), stop=max_idx)\n",
        "  val_idx = val_idx.tolist()\n",
        "\n",
        "  max_values = np.zeros((NUM_FEATURES,))\n",
        "  max_labels = 0.0\n",
        "  num_positives= 0\n",
        "  with tf.io.TFRecordWriter(os.path.join(save_path, name + '_train.tfrec')) as writer:\n",
        "    for i in train_idx:\n",
        "      sub_data = data[i:i+256,:]\n",
        "\n",
        "      mx1 = np.max(sub_data, axis= 0)\n",
        "      max_values[np.where(mx1>max_values)] = mx1[np.where(mx1>max_values)]\n",
        "\n",
        "      label = data[i+256,3]\n",
        "      if label>max_labels:\n",
        "        max_labels = label\n",
        "      #if data[i+256,3]> data[i+256-1,3] :\n",
        "      #  label = 1\n",
        "      #  num_positives += 1\n",
        "\n",
        "      example = serialize_example(sub_data.reshape(-1,1), label)\n",
        "      writer.write(example)\n",
        "  print('Class 1:',num_positives )\n",
        "  num_positives = 0\n",
        "  with tf.io.TFRecordWriter(os.path.join(save_path, name + '_val.tfrec')) as writer:\n",
        "    for i in val_idx:\n",
        "      sub_data = data[i:i+256,:]\n",
        "      #label = 0\n",
        "      #if data[i+256,3]> data[i+256-1,3] :\n",
        "      #  label = 1\n",
        "      #  num_positives += 1\n",
        "      label = data[i+256,3]\n",
        "      example = serialize_example(sub_data.reshape(-1,1), label)\n",
        "      writer.write(example)\n",
        "  print('Class 1:VAL:',num_positives )\n",
        "  return len(train_idx), len(val_idx), max_values,max_labels"
      ],
      "metadata": {
        "id": "PJKEo4J2DgFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv=  '/content/drive/MyDrive/5min/BTCUSDT.csv'\n",
        "num_train_samples, num_val_samples, max_values,max_labels = create_tfrecs(path_to_csv ,save_path = '/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr_f_sSKkwRu",
        "outputId": "a01004d5-2da3-4f9d-f577-f5d39c893cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1: 0\n",
            "Class 1:VAL: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fww9pi_SRB70",
        "outputId": "aeaa073e-3cda-44aa-ef2d-1d5e159526be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.97620000e+04, 1.97986800e+04, 1.97290300e+04, 1.97620000e+04,\n",
              "       8.27717230e+03, 7.78004571e+07, 5.83840000e+04, 4.95984888e+03,\n",
              "       3.96974091e+07, 7.99473710e+04])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cymoOpV0KMOO",
        "outputId": "787db7be-c9fe-466b-b00c-acf523019458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "317363"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9oU-hzHO95u",
        "outputId": "339b1ecc-c0f7-4e48-f1a6-fa190b5d32f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19762.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVTYD7mUKNGR",
        "outputId": "266de84b-1b66-4910-ed6e-732c2238d9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136014"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvrTDt59QFDe",
        "outputId": "287e833b-b140-4a38-9edc-cea0b4502eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19762.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples = 353634"
      ],
      "metadata": {
        "id": "nRAY_QuZIFI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "176605/num_train_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soVXApaO3KNw",
        "outputId": "6db8d60d-1a61-4c17-8d37-9808396d973d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4994005101319443"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples = 99743"
      ],
      "metadata": {
        "id": "AFTKN3F7IPOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "49710/num_val_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVVWWJQH3Qm6",
        "outputId": "53e96a61-a853-4e68-d02a-ed619c018b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4983808387556019"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary describing the features.\n",
        "feature_description = {\n",
        "    'data': tf.io.FixedLenFeature([TIME_STEP*NUM_FEATURES], tf.float32, default_value=[0.0]*256*NUM_FEATURES),\n",
        "    'target': tf.io.FixedLenFeature([1], tf.float32, default_value=[0.0]),\n",
        "  }\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "  # Parse the input tf.train.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "def preprocess(features,effesionet=True):\n",
        "  data = features['data']\n",
        "  #data = tf.io.decode_raw(data, tf.int16)\n",
        "  label = features['target']\n",
        "  #label = tf.io.decode_raw(label, tf.int16)\n",
        "  return data, label\n",
        "\n",
        "\n",
        "def normalize(data ,label):\n",
        "  #standard\n",
        "  data = tf.cast(data, tf.float32)\n",
        "  scale = tf.constant(max_values.astype(np.float32))\n",
        "\n",
        "  label = tf.cast(label, tf.float32)\n",
        "  data /= scale\n",
        "  label /= tf.constant(np.float32(max_labels))\n",
        "  return data , label\n",
        "\n",
        "@tf.function\n",
        "def augment(data,label):\n",
        "\n",
        "  return data , label\n",
        "\n",
        "def Resize(data,label):\n",
        "  data = tf.reshape(data, [TIME_STEP,NUM_FEATURES])\n",
        "  #label = tf.reshape(label, [256,1])\n",
        "  return data , label\n"
      ],
      "metadata": {
        "id": "KH6dvsAwlzPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tf.data.TFRecordDataset(['/content/BTCUSDT_train.tfrec'])\n",
        "ds_train = ds_train.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(100)\n",
        "ds_train  =  ds_train.map(preprocess)#.map(agment)\n",
        "ds_train  = ds_train.map(Resize).map(normalize).batch(BATCH_SIZE,drop_remainder=True).repeat()"
      ],
      "metadata": {
        "id": "JtByfC1nnQOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val = tf.data.TFRecordDataset(['/content/BTCUSDT_val.tfrec'])\n",
        "ds_val = ds_val.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_val  =  ds_val.map(preprocess)#.map(agment)\n",
        "ds_val  = ds_val.map(Resize).map(normalize).batch(BATCH_SIZE,drop_remainder=True).repeat()"
      ],
      "metadata": {
        "id": "6hceKpqH9-3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1, label = next(iter(ds_val))\n",
        "data1.shape"
      ],
      "metadata": {
        "id": "sA5kB2EnsZm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d7e5b9-f8cd-4d4c-b569-23d0ef01f24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 256, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC2N1n21uw7c",
        "outputId": "99af9e8a-d82c-4bd8-f59d-c274e0ae60a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 1), dtype=float32, numpy=\n",
              "array([[0.581301  ],\n",
              "       [0.58146745],\n",
              "       [0.58164406],\n",
              "       [0.5825782 ],\n",
              "       [0.5829511 ],\n",
              "       [0.5824173 ],\n",
              "       [0.58233273],\n",
              "       [0.58183026],\n",
              "       [0.5817726 ],\n",
              "       [0.5817792 ],\n",
              "       [0.5817589 ],\n",
              "       [0.58195376],\n",
              "       [0.58178324],\n",
              "       [0.58141434],\n",
              "       [0.58118916],\n",
              "       [0.5810803 ],\n",
              "       [0.581848  ],\n",
              "       [0.58136624],\n",
              "       [0.5810176 ],\n",
              "       [0.5816638 ],\n",
              "       [0.58089566],\n",
              "       [0.5811264 ],\n",
              "       [0.58107275],\n",
              "       [0.580424  ],\n",
              "       [0.5809316 ],\n",
              "       [0.5813875 ],\n",
              "       [0.5809776 ],\n",
              "       [0.5802368 ],\n",
              "       [0.58124787],\n",
              "       [0.5805663 ],\n",
              "       [0.5820205 ],\n",
              "       [0.58135813],\n",
              "       [0.5806988 ],\n",
              "       [0.5809776 ],\n",
              "       [0.5803881 ],\n",
              "       [0.58010167],\n",
              "       [0.57995397],\n",
              "       [0.58043164],\n",
              "       [0.5801913 ],\n",
              "       [0.5799641 ],\n",
              "       [0.5802419 ],\n",
              "       [0.58072263],\n",
              "       [0.5804073 ],\n",
              "       [0.58055663],\n",
              "       [0.58101004],\n",
              "       [0.58167034],\n",
              "       [0.5817655 ],\n",
              "       [0.5826738 ],\n",
              "       [0.5828241 ],\n",
              "       [0.58267283],\n",
              "       [0.5835361 ],\n",
              "       [0.58273154],\n",
              "       [0.583443  ],\n",
              "       [0.58295214],\n",
              "       [0.5828302 ],\n",
              "       [0.58328664],\n",
              "       [0.5831839 ],\n",
              "       [0.582644  ],\n",
              "       [0.58172655],\n",
              "       [0.5817281 ],\n",
              "       [0.5816547 ],\n",
              "       [0.5815312 ],\n",
              "       [0.582268  ],\n",
              "       [0.5818247 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "id": "6HFidQPB81Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.data.TFRecordDataset(['/content/BTCUSDT_val.tfrec'])\n",
        "a = a.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "a  =  a.map(preprocess)#.map(agment)\n",
        "a  = a.map(Resize).map(normalize).batch(BATCH_SIZE,drop_remainder=True)\n",
        "mx = 0.0\n",
        "for b in a:\n",
        "  d, l = b\n",
        "  l = l.numpy()\n",
        "  m = np.max(l)\n",
        "  if m>mx:\n",
        "    mx=m\n",
        "print(mx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7eqY8CS8mHN",
        "outputId": "67112c3e-72be-406b-8191-1a41f5df5179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4781022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.activations import selu, relu\n",
        "\n",
        "class BB (tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               filters = 64,\n",
        "               kernel_size = 9):\n",
        "    super(BB, self).__init__()\n",
        "\n",
        "    self.filters = filters\n",
        "    self.kernel_size = kernel_size\n",
        "\n",
        "    self.conv1 = tf.keras.layers.Conv1D(filters, kernel_size, activation=None, padding='same')\n",
        "\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "    self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "    self.conv2 = tf.keras.layers.Conv1D(filters, kernel_size, activation=None, padding='same')\n",
        "\n",
        "\n",
        "  def call(self, z, training = True):\n",
        "    x = self.conv1(z)\n",
        "    x = self.bn1(x, training = training)\n",
        "    x = selu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x, training = training)\n",
        "    x = selu(x)\n",
        "    x = tf.keras.layers.Add()([x, z])\n",
        "\n",
        "    x = self.bn3(x, training = training)\n",
        "    x = selu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "1m72jH-n3pWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_max_pool_with_masks(x,\n",
        "                           ksize = [1,1,2,1],\n",
        "                           strides = [1,1,2,1],\n",
        "                           padding = \"VALID\",\n",
        "                           data_format='NHWC',\n",
        "                           output_dtype=tf.dtypes.int64,\n",
        "                           include_batch_in_index=True):\n",
        "  \"\"\"\n",
        "    x = input tensor of size BTC, B=Batch, T:Time step, C:Channel\n",
        "    ksize: kernel size for each dim\n",
        "    strides: strides of each dim\n",
        "    data_format:channel last or not\n",
        "    output_dtype: int64 or int32\n",
        "    include_batch_in_index:An optional boolean. Defaults to True. Whether to include batch dimension in flattened index of argmax.\n",
        "  \"\"\"\n",
        "  input = tf.reshape(x, shape=(x.shape[0], 1, x.shape[1],x.shape[2]))\n",
        "  output, argmax = tf.nn.max_pool_with_argmax(input,\n",
        "                                              ksize = [1,1,2,1],\n",
        "                                              strides = [1,1,2,1],\n",
        "                                              padding = \"VALID\",\n",
        "                                              data_format='NHWC',\n",
        "                                              output_dtype=tf.dtypes.int64,\n",
        "                                              include_batch_in_index=True\n",
        "                                              )\n",
        "\n",
        "  #a = tf.reshape(output, shape=(-1,1))\n",
        "  indices = tf.reshape(argmax, shape=(-1,1))\n",
        "  input_flatten = tf.reshape(input, shape=(-1,1))\n",
        "  tensor = tf.zeros_like(input_flatten, dtype=tf.float32)\n",
        "  updates = tf.ones_like(indices, dtype=tf.float32)\n",
        "  mask = tf.tensor_scatter_nd_update(tensor, indices, updates)\n",
        "  mask = tf.reshape(mask, shape=x.get_shape().as_list())\n",
        "  output = tf.reshape(output, shape=(output.shape[0],output.shape[2],output.shape[3]))\n",
        "  return output, mask"
      ],
      "metadata": {
        "id": "cZkzYlN8-ZYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class eUNet1D (keras.Model):\n",
        "  def __init__(self,\n",
        "               kernel_size = 9,\n",
        "               strides = 2):\n",
        "    super(eUNet1D, self).__init__()\n",
        "    self.kernel_size        = kernel_size\n",
        "    self.strides            = strides\n",
        "    self.conv1_0 = tf.keras.layers.Conv1D(64, kernel_size, activation='selu', padding='same')\n",
        "    self.bb1_1 = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb1_2 = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv2_0 = tf.keras.layers.Conv1D(128, kernel_size, activation='selu', padding='same')\n",
        "    self.bb2_1 = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb2_2 = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv3_0 = tf.keras.layers.Conv1D(256, kernel_size, activation='selu', padding='same')\n",
        "    self.bb3_1 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb3_2 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb3_3 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down4 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv4_0 = tf.keras.layers.Conv1D(512, kernel_size, activation='selu', padding='same')\n",
        "    self.bb4_1 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb4_2 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb4_3 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down5 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.bb5_1 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_2 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_3 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "\n",
        "    self.bb5_1_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_2_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_3_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.up5 =  tf.keras.layers.Conv1DTranspose(filters = 512, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv4_0_ = tf.keras.layers.Conv1D(256, kernel_size, activation='selu', padding='same')\n",
        "    self.bb4_1_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb4_2_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb4_3_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.up4 =  tf.keras.layers.Conv1DTranspose(filters = 256, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv3_0_ = tf.keras.layers.Conv1D(128, kernel_size, activation='selu', padding='same')\n",
        "    self.bb3_1_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb3_2_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb3_3_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.up3 =  tf.keras.layers.Conv1DTranspose(filters = 128, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv2_0_ = tf.keras.layers.Conv1D(64, kernel_size, activation='selu', padding='same')\n",
        "    self.bb2_1_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb2_2_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.up2 =  tf.keras.layers.Conv1DTranspose(filters = 64, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.bb1_1_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb1_2_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    #self.up1 =  tf.keras.layers.Conv1DTranspose(filters = 64, kernel_size = 2, strides=self.strides, padding='same')\n",
        "    self.conv_out = tf.keras.layers.Conv1D(16, 1, activation='selu')#256*16\n",
        "\n",
        "    #self.conv_out1 = tf.keras.layers.Conv1D(8, self.strides, activation='relu', padding='same')\n",
        "    #self.f = tf.keras.layers.Flatten()\n",
        "    '''\n",
        "    self.bn = tf.keras.layers.BatchNormalization(axis=-1)\n",
        "    self.gap = tf.keras.layers.GlobalAveragePooling1D()\n",
        "    self.do = tf.keras.layers.Dropout(0.2)\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    '''\n",
        "    self.conv_out2_1 = tf.keras.layers.Conv1D(4, self.strides, activation='relu', padding='same')\n",
        "    self.mp2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#32*4\n",
        "    self.f = tf.keras.layers.Flatten()\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    self.conv_out2_2 = tf.keras.layers.Conv1D(4, self.strides, activation='relu', padding='same')\n",
        "    self.mp3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=16, padding='valid')#1*4\n",
        "\n",
        "    self.conv_out3 = tf.keras.layers.Conv1D(1, self.strides, activation='relu', padding='same')#1*1\n",
        "    self.rs = tf.keras.layers.Reshape((BATCH_SIZE, 1))\n",
        "\n",
        "\n",
        "\n",
        "  def call(self, z, training = True):\n",
        "    \"\"\"\n",
        "      z: (btach, time steps, channels)--> input\n",
        "    \"\"\"\n",
        "    #######################################\n",
        "    ############ Row 1 ####################\n",
        "    #######################################\n",
        "    x = self.conv1_0(z)#(None, 256, 64)\n",
        "    x = self.bb1_1(x) #(None, 256, 64)\n",
        "    x1 = self.bb1_2(x) #(None, 256, 64)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 2 ####################\n",
        "    #######################################\n",
        "    x, mask2 = tf_max_pool_with_masks(x1) #(None, 128, 64)\n",
        "    x = self.conv2_0(x)\n",
        "    x = self.bb2_1(x) #(None, 128, 128)\n",
        "    x2 = self.bb2_2(x) #(None, 128, 128)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 3 ####################\n",
        "    #######################################\n",
        "    x, mask3 = tf_max_pool_with_masks(x2) #(None, 64, 128)\n",
        "    x = self.conv3_0(x)\n",
        "    x = self.bb3_1(x) #(None, 64, 256)\n",
        "    x = self.bb3_2(x) #(None, 64, 256)\n",
        "    x3 = self.bb3_3(x) #(None, 64, 256)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 4 ####################\n",
        "    #######################################\n",
        "    x, mask4 = tf_max_pool_with_masks(x3) #(None, 32, 256)\n",
        "    x = self.conv4_0(x)\n",
        "    x = self.bb4_1(x) #(None, 32, 512)\n",
        "    x = self.bb4_2(x) #(None, 32, 512)\n",
        "    x4 = self.bb4_3(x) #(None, 32, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 5 ####################\n",
        "    #######################################\n",
        "    x, mask5 = tf_max_pool_with_masks(x4) #(None, 16, 512)\n",
        "    x = self.bb5_1(x) #(None, 16, 512)\n",
        "    x = self.bb5_2(x) #(None, 16, 512)\n",
        "    x = self.bb5_3(x) #(None, 16, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 5_1 ##################\n",
        "    #######################################\n",
        "    x = self.bb5_1_(x) #(None, 16, 512)\n",
        "    x = self.bb5_2_(x) #(None, 16, 512)\n",
        "    x = self.bb5_3_(x) #(None, 16, 512)\n",
        "    x = self.up5(x) #(None, 32, 512)\n",
        "    x = tf.math.multiply(x, mask5) #(None, 32, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 4_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x4]) #(None, 32, 512)\n",
        "    x = self.conv4_0_(x)\n",
        "    x = self.bb4_1_(x) #(None, 32, 256)\n",
        "    x = self.bb4_2_(x) #(None, 32, 256)\n",
        "    x = self.bb4_3_(x) #(None, 32, 256)\n",
        "    x = self.up4(x) #(None, 64, 256)\n",
        "    x = tf.math.multiply(x, mask4) #(None, 64, 256)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 3_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x3]) #(None, 64, 256)\n",
        "    x = self.conv3_0_(x)\n",
        "    x = self.bb3_1_(x) #(None, 64, 128)\n",
        "    x = self.bb3_2_(x) #(None, 64, 128)\n",
        "    x = self.bb3_3_(x) #(None, 64, 128)\n",
        "    x = self.up3(x) #(None, 128, 128)\n",
        "    x = tf.math.multiply(x, mask3) #(None, 128, 128)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 2_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x2]) #(None, 128, 128)\n",
        "    x = self.conv2_0_(x)\n",
        "    x = self.bb2_1_(x) #(None, 128, 64)\n",
        "    x = self.bb2_2_(x) #(None, 128, 64)\n",
        "    x = self.up2(x) #(None, 256, 64)\n",
        "    x = tf.math.multiply(x, mask2) #(None, 256, 64)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 1_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x1]) #(None, 256, 64)\n",
        "    x = self.bb1_1_(x) #(None, 256, 64)\n",
        "    x = self.bb1_2_(x) #(None, 256, 64)\n",
        "\n",
        "    x = self.conv_out(x)#(None, 256, 16)\n",
        "    '''\n",
        "    x = self.bn(x)\n",
        "    x = self.gap(x)\n",
        "    x = self.do(x)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    '''\n",
        "    x = self.conv_out2_1(x)\n",
        "    x = self.mp2(x)#(None, 16, 4)\n",
        "    x = self.f(x)\n",
        "    x = self.fc(x)\n",
        "    '''\n",
        "    self.conv_out2_1 = tf.keras.layers.Conv1D(4, self.strides, activation='relu', padding='same')\n",
        "    self.mp2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#32*4\n",
        "    self.f = tf.keras.layers.Flatten()\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "\n",
        "    x = self.conv_out2_2(x)\n",
        "    x = self.mp3(x)#(None, 1, 4)\n",
        "\n",
        "    x = self.conv_out3(x)\n",
        "    x = self.mp3(x)#(None, 1, 1)\n",
        "    x = tf.reshape(x, (x.shape[0],1))\n",
        "    '''\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "lbkEtYgL-g_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class eUNet1D (keras.Model):\n",
        "  def __init__(self,\n",
        "               kernel_size = 9,\n",
        "               strides = 2):\n",
        "    super(eUNet1D, self).__init__()\n",
        "    self.kernel_size        = kernel_size\n",
        "    self.strides            = strides\n",
        "    self.conv1_0 = tf.keras.layers.Conv1D(64, kernel_size, activation='selu', padding='same')\n",
        "    self.bb1_1 = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb1_2 = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv2_0 = tf.keras.layers.Conv1D(128, kernel_size, activation='selu', padding='same')\n",
        "    self.bb2_1 = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb2_2 = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv3_0 = tf.keras.layers.Conv1D(256, kernel_size, activation='selu', padding='same')\n",
        "    self.bb3_1 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb3_2 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb3_3 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down4 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv4_0 = tf.keras.layers.Conv1D(512, kernel_size, activation='selu', padding='same')\n",
        "    self.bb4_1 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb4_2 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb4_3 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down5 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.bb5_1 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_2 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_3 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "\n",
        "    self.bb5_1_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_2_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_3_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.up5 =  tf.keras.layers.Conv1DTranspose(filters = 512, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv4_0_ = tf.keras.layers.Conv1D(256, kernel_size, activation='selu', padding='same')\n",
        "    self.bb4_1_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb4_2_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb4_3_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.up4 =  tf.keras.layers.Conv1DTranspose(filters = 256, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv3_0_ = tf.keras.layers.Conv1D(128, kernel_size, activation='selu', padding='same')\n",
        "    self.bb3_1_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb3_2_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb3_3_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.up3 =  tf.keras.layers.Conv1DTranspose(filters = 128, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv2_0_ = tf.keras.layers.Conv1D(64, kernel_size, activation='selu', padding='same')\n",
        "    self.bb2_1_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb2_2_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.up2 =  tf.keras.layers.Conv1DTranspose(filters = 64, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.bb1_1_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb1_2_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    #self.up1 =  tf.keras.layers.Conv1DTranspose(filters = 64, kernel_size = 2, strides=self.strides, padding='same')\n",
        "    self.conv_out = tf.keras.layers.Conv1D(64, 1, activation='selu')#256*16\n",
        "\n",
        "    #self.conv_out1 = tf.keras.layers.Conv1D(8, self.strides, activation='relu', padding='same')\n",
        "    #self.f = tf.keras.layers.Flatten()\n",
        "    '''\n",
        "    self.bn = tf.keras.layers.BatchNormalization(axis=-1)\n",
        "    self.gap = tf.keras.layers.GlobalAveragePooling1D()\n",
        "    self.do = tf.keras.layers.Dropout(0.2)\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    '''\n",
        "    self.conv_out2_1 = tf.keras.layers.Conv1D(32, self.strides, activation='relu', padding='same')\n",
        "    self.mp2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#32*32\n",
        "\n",
        "    self.conv_out3_1 = tf.keras.layers.Conv1D(32, self.strides, activation='relu', padding='same')\n",
        "    self.mp3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#4*32\n",
        "\n",
        "    self.f = tf.keras.layers.Flatten()\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    '''\n",
        "    self.conv_out2_2 = tf.keras.layers.Conv1D(4, self.strides, activation='relu', padding='same')\n",
        "    self.mp3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=16, padding='valid')#1*4\n",
        "\n",
        "    self.conv_out3 = tf.keras.layers.Conv1D(1, self.strides, activation='relu', padding='same')#1*1\n",
        "    self.rs = tf.keras.layers.Reshape((BATCH_SIZE, 1))\n",
        "    '''\n",
        "\n",
        "\n",
        "  def call(self, z, training = True):\n",
        "    \"\"\"\n",
        "      z: (btach, time steps, channels)--> input\n",
        "    \"\"\"\n",
        "    #######################################\n",
        "    ############ Row 1 ####################\n",
        "    #######################################\n",
        "    x = self.conv1_0(z)#(None, 256, 64)\n",
        "    x = self.bb1_1(x) #(None, 256, 64)\n",
        "    x1 = self.bb1_2(x) #(None, 256, 64)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 2 ####################\n",
        "    #######################################\n",
        "    x, mask2 = tf_max_pool_with_masks(x1) #(None, 128, 64)\n",
        "    x = self.conv2_0(x)\n",
        "    x = self.bb2_1(x) #(None, 128, 128)\n",
        "    x2 = self.bb2_2(x) #(None, 128, 128)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 3 ####################\n",
        "    #######################################\n",
        "    x, mask3 = tf_max_pool_with_masks(x2) #(None, 64, 128)\n",
        "    x = self.conv3_0(x)\n",
        "    x = self.bb3_1(x) #(None, 64, 256)\n",
        "    x = self.bb3_2(x) #(None, 64, 256)\n",
        "    x3 = self.bb3_3(x) #(None, 64, 256)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 4 ####################\n",
        "    #######################################\n",
        "    x, mask4 = tf_max_pool_with_masks(x3) #(None, 32, 256)\n",
        "    x = self.conv4_0(x)\n",
        "    x = self.bb4_1(x) #(None, 32, 512)\n",
        "    x = self.bb4_2(x) #(None, 32, 512)\n",
        "    x4 = self.bb4_3(x) #(None, 32, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 5 ####################\n",
        "    #######################################\n",
        "    x, mask5 = tf_max_pool_with_masks(x4) #(None, 16, 512)\n",
        "    x = self.bb5_1(x) #(None, 16, 512)\n",
        "    x = self.bb5_2(x) #(None, 16, 512)\n",
        "    x = self.bb5_3(x) #(None, 16, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 5_1 ##################\n",
        "    #######################################\n",
        "    x = self.bb5_1_(x) #(None, 16, 512)\n",
        "    x = self.bb5_2_(x) #(None, 16, 512)\n",
        "    x = self.bb5_3_(x) #(None, 16, 512)\n",
        "    x = self.up5(x) #(None, 32, 512)\n",
        "    x = tf.math.multiply(x, mask5) #(None, 32, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 4_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x4]) #(None, 32, 512)\n",
        "    x = self.conv4_0_(x)\n",
        "    x = self.bb4_1_(x) #(None, 32, 256)\n",
        "    x = self.bb4_2_(x) #(None, 32, 256)\n",
        "    x = self.bb4_3_(x) #(None, 32, 256)\n",
        "    x = self.up4(x) #(None, 64, 256)\n",
        "    x = tf.math.multiply(x, mask4) #(None, 64, 256)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 3_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x3]) #(None, 64, 256)\n",
        "    x = self.conv3_0_(x)\n",
        "    x = self.bb3_1_(x) #(None, 64, 128)\n",
        "    x = self.bb3_2_(x) #(None, 64, 128)\n",
        "    x = self.bb3_3_(x) #(None, 64, 128)\n",
        "    x = self.up3(x) #(None, 128, 128)\n",
        "    x = tf.math.multiply(x, mask3) #(None, 128, 128)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 2_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x2]) #(None, 128, 128)\n",
        "    x = self.conv2_0_(x)\n",
        "    x = self.bb2_1_(x) #(None, 128, 64)\n",
        "    x = self.bb2_2_(x) #(None, 128, 64)\n",
        "    x = self.up2(x) #(None, 256, 64)\n",
        "    x = tf.math.multiply(x, mask2) #(None, 256, 64)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 1_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x1]) #(None, 256, 64)\n",
        "    x = self.bb1_1_(x) #(None, 256, 64)\n",
        "    x = self.bb1_2_(x) #(None, 256, 64)\n",
        "\n",
        "    x = self.conv_out(x)#(None, 256, 16)\n",
        "    '''\n",
        "    x = self.bn(x)\n",
        "    x = self.gap(x)\n",
        "    x = self.do(x)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    '''\n",
        "    x = self.conv_out2_1(x)\n",
        "    x = self.mp2(x)#(None, 16, 4)\n",
        "    x = self.f(x)\n",
        "    x = self.fc(x)\n",
        "    '''\n",
        "    self.conv_out2_1 = tf.keras.layers.Conv1D(4, self.strides, activation='relu', padding='same')\n",
        "    self.mp2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#32*4\n",
        "    self.f = tf.keras.layers.Flatten()\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "\n",
        "    x = self.conv_out2_2(x)\n",
        "    x = self.mp3(x)#(None, 1, 4)\n",
        "\n",
        "    x = self.conv_out3(x)\n",
        "    x = self.mp3(x)#(None, 1, 1)\n",
        "    x = tf.reshape(x, (x.shape[0],1))\n",
        "    '''\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "NRw3YCEfMglb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class eUNet1D (keras.Model):\n",
        "  def __init__(self,\n",
        "               kernel_size = 9,\n",
        "               strides = 2):\n",
        "    super(eUNet1D, self).__init__()\n",
        "    self.kernel_size        = kernel_size\n",
        "    self.strides            = strides\n",
        "    self.conv1_0 = tf.keras.layers.Conv1D(64, kernel_size, activation='relu', padding='same')\n",
        "    self.bb1_1 = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb1_2 = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv2_0 = tf.keras.layers.Conv1D(128, kernel_size, activation='relu', padding='same')\n",
        "    self.bb2_1 = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb2_2 = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv3_0 = tf.keras.layers.Conv1D(256, kernel_size, activation='relu', padding='same')\n",
        "    self.bb3_1 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb3_2 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb3_3 = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down4 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.conv4_0 = tf.keras.layers.Conv1D(512, kernel_size, activation='relu', padding='same')\n",
        "    self.bb4_1 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb4_2 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb4_3 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "\n",
        "    #self.down5 = tf.keras.layers.MaxPool1D(pool_size=2, strides=self.strides, padding='valid')\n",
        "    self.bb5_1 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_2 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_3 = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "\n",
        "    self.bb5_1_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_2_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.bb5_3_ = BB(filters = 512, kernel_size = self.kernel_size)\n",
        "    self.up5 =  tf.keras.layers.Conv1DTranspose(filters = 512, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv4_0_ = tf.keras.layers.Conv1D(256, kernel_size, activation='relu', padding='same')\n",
        "    self.bb4_1_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb4_2_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.bb4_3_ = BB(filters = 256, kernel_size = self.kernel_size)\n",
        "    self.up4 =  tf.keras.layers.Conv1DTranspose(filters = 256, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv3_0_ = tf.keras.layers.Conv1D(128, kernel_size, activation='relu', padding='same')\n",
        "    self.bb3_1_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb3_2_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.bb3_3_ = BB(filters = 128, kernel_size = self.kernel_size)\n",
        "    self.up3 =  tf.keras.layers.Conv1DTranspose(filters = 128, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.conv2_0_ = tf.keras.layers.Conv1D(64, kernel_size, activation='relu', padding='same')\n",
        "    self.bb2_1_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb2_2_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.up2 =  tf.keras.layers.Conv1DTranspose(filters = 64, kernel_size = 2, strides=self.strides, padding='valid')\n",
        "\n",
        "    self.bb1_1_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    self.bb1_2_ = BB(filters = 64, kernel_size = self.kernel_size)\n",
        "    #self.up1 =  tf.keras.layers.Conv1DTranspose(filters = 64, kernel_size = 2, strides=self.strides, padding='same')\n",
        "    self.conv_out = tf.keras.layers.Conv1D(16, 1, activation='relu')#256*16\n",
        "\n",
        "    #self.conv_out1 = tf.keras.layers.Conv1D(8, self.strides, activation='relu', padding='same')\n",
        "    #self.f = tf.keras.layers.Flatten()\n",
        "    '''\n",
        "    self.bn = tf.keras.layers.BatchNormalization(axis=-1)\n",
        "    self.gap = tf.keras.layers.GlobalAveragePooling1D()\n",
        "    self.do = tf.keras.layers.Dropout(0.2)\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    '''\n",
        "    self.lstm1 = tf.keras.layers.LSTM(units = 60, activation = 'relu', return_sequences = True)\n",
        "    self.lstm2 = tf.keras.layers.LSTM(units = 80, activation = 'relu', return_sequences = True)\n",
        "    self.lstm3 = tf.keras.layers.LSTM(units = 120, activation = 'relu')\n",
        "\n",
        "    self.f = tf.keras.layers.Flatten()\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='relu')\n",
        "    '''\n",
        "    self.conv_out2_1 = tf.keras.layers.Conv1D(32, self.strides, activation='relu', padding='same')\n",
        "    self.mp2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#32*32\n",
        "\n",
        "    self.conv_out3_1 = tf.keras.layers.Conv1D(32, self.strides, activation='relu', padding='same')\n",
        "    self.mp3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#4*32\n",
        "\n",
        "    self.f = tf.keras.layers.Flatten()\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    '''\n",
        "    '''\n",
        "    self.conv_out2_2 = tf.keras.layers.Conv1D(4, self.strides, activation='relu', padding='same')\n",
        "    self.mp3 = tf.keras.layers.MaxPool1D(pool_size=2, strides=16, padding='valid')#1*4\n",
        "\n",
        "    self.conv_out3 = tf.keras.layers.Conv1D(1, self.strides, activation='relu', padding='same')#1*1\n",
        "    self.rs = tf.keras.layers.Reshape((BATCH_SIZE, 1))\n",
        "    '''\n",
        "\n",
        "\n",
        "  def call(self, z, training = True):\n",
        "    \"\"\"\n",
        "      z: (btach, time steps, channels)--> input\n",
        "    \"\"\"\n",
        "    #######################################\n",
        "    ############ Row 1 ####################\n",
        "    #######################################\n",
        "    inputs = z\n",
        "    x = self.conv1_0(z)#(None, 256, 64)\n",
        "    x = self.bb1_1(x) #(None, 256, 64)\n",
        "    x1 = self.bb1_2(x) #(None, 256, 64)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 2 ####################\n",
        "    #######################################\n",
        "    x, mask2 = tf_max_pool_with_masks(x1) #(None, 128, 64)\n",
        "    x = self.conv2_0(x)\n",
        "    x = self.bb2_1(x) #(None, 128, 128)\n",
        "    x2 = self.bb2_2(x) #(None, 128, 128)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 3 ####################\n",
        "    #######################################\n",
        "    x, mask3 = tf_max_pool_with_masks(x2) #(None, 64, 128)\n",
        "    x = self.conv3_0(x)\n",
        "    x = self.bb3_1(x) #(None, 64, 256)\n",
        "    x = self.bb3_2(x) #(None, 64, 256)\n",
        "    x3 = self.bb3_3(x) #(None, 64, 256)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 4 ####################\n",
        "    #######################################\n",
        "    x, mask4 = tf_max_pool_with_masks(x3) #(None, 32, 256)\n",
        "    x = self.conv4_0(x)\n",
        "    x = self.bb4_1(x) #(None, 32, 512)\n",
        "    x = self.bb4_2(x) #(None, 32, 512)\n",
        "    x4 = self.bb4_3(x) #(None, 32, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 5 ####################\n",
        "    #######################################\n",
        "    x, mask5 = tf_max_pool_with_masks(x4) #(None, 16, 512)\n",
        "    x = self.bb5_1(x) #(None, 16, 512)\n",
        "    x = self.bb5_2(x) #(None, 16, 512)\n",
        "    x = self.bb5_3(x) #(None, 16, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 5_1 ##################\n",
        "    #######################################\n",
        "    x = self.bb5_1_(x) #(None, 16, 512)\n",
        "    x = self.bb5_2_(x) #(None, 16, 512)\n",
        "    x = self.bb5_3_(x) #(None, 16, 512)\n",
        "    x = self.up5(x) #(None, 32, 512)\n",
        "    x = tf.math.multiply(x, mask5) #(None, 32, 512)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 4_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x4]) #(None, 32, 512)\n",
        "    x = self.conv4_0_(x)\n",
        "    x = self.bb4_1_(x) #(None, 32, 256)\n",
        "    x = self.bb4_2_(x) #(None, 32, 256)\n",
        "    x = self.bb4_3_(x) #(None, 32, 256)\n",
        "    x = self.up4(x) #(None, 64, 256)\n",
        "    x = tf.math.multiply(x, mask4) #(None, 64, 256)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 3_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x3]) #(None, 64, 256)\n",
        "    x = self.conv3_0_(x)\n",
        "    x = self.bb3_1_(x) #(None, 64, 128)\n",
        "    x = self.bb3_2_(x) #(None, 64, 128)\n",
        "    x = self.bb3_3_(x) #(None, 64, 128)\n",
        "    x = self.up3(x) #(None, 128, 128)\n",
        "    x = tf.math.multiply(x, mask3) #(None, 128, 128)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 2_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x2]) #(None, 128, 128)\n",
        "    x = self.conv2_0_(x)\n",
        "    x = self.bb2_1_(x) #(None, 128, 64)\n",
        "    x = self.bb2_2_(x) #(None, 128, 64)\n",
        "    x = self.up2(x) #(None, 256, 64)\n",
        "    x = tf.math.multiply(x, mask2) #(None, 256, 64)\n",
        "\n",
        "    #######################################\n",
        "    ############ Row 1_1 ##################\n",
        "    #######################################\n",
        "    x = tf.keras.layers.Add()([x, x1]) #(None, 256, 64)\n",
        "    x = self.bb1_1_(x) #(None, 256, 64)\n",
        "    x = self.bb1_2_(x) #(None, 256, 64)\n",
        "\n",
        "    x = self.conv_out(x)#(None, 256, 16)\n",
        "    '''\n",
        "    x = self.bn(x)\n",
        "    x = self.gap(x)\n",
        "    x = self.do(x)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    '''\n",
        "    #print(x.shape)\n",
        "\n",
        "    x = tf.concat([x, inputs], -1)\n",
        "    x = self.lstm1(x)\n",
        "    x = self.lstm2(x)\n",
        "    x = self.lstm3(x)\n",
        "    #x = self.f(x)\n",
        "    x = self.fc(x)\n",
        "    '''\n",
        "    self.conv_out2_1 = tf.keras.layers.Conv1D(4, self.strides, activation='relu', padding='same')\n",
        "    self.mp2 = tf.keras.layers.MaxPool1D(pool_size=2, strides=8, padding='valid')#32*4\n",
        "    self.f = tf.keras.layers.Flatten()\n",
        "    self.fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "\n",
        "    x = self.conv_out2_2(x)\n",
        "    x = self.mp3(x)#(None, 1, 4)\n",
        "\n",
        "    x = self.conv_out3(x)\n",
        "    x = self.mp3(x)#(None, 1, 1)\n",
        "    x = tf.reshape(x, (x.shape[0],1))\n",
        "    '''\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "IoM1nQR_Psjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(1.0, dtype=tf.float32, shape=(7,256,10))*np.random.rand()\n",
        "model = eUNet1D(kernel_size = 9)\n",
        "temp_out = model(x, training = False)\n",
        "temp_out.shape"
      ],
      "metadata": {
        "id": "Ut6DqJuaIfIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f380786-0253-4d1c-f487-64d993fcf88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTkp6j7OI4h2",
        "outputId": "78643b72-4bc7-47d7-8aaa-73dc17bde8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7, 1), dtype=float32, numpy=\n",
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_STEPS = num_train_samples//BATCH_SIZE+1\n",
        "VAL_STEPS = num_val_samples//BATCH_SIZE"
      ],
      "metadata": {
        "id": "Yd9kYGeBJEbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cce_with_label_smoothing(y_true,y_pred):\n",
        "  return tf.keras.losses.binary_crossentropy(y_true,y_pred,label_smoothing=0.2)"
      ],
      "metadata": {
        "id": "Bm39vtXoBTpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "lr_sc = tf.keras.optimizers.schedules.ExponentialDecay(1e-4, TRAIN_STEPS ,decay_rate=0.96)\n",
        "optimizer = tf.keras.optimizers.Adam(1e-3,beta_1=0.9,beta_2=0.999)\n",
        "model.compile(loss= 'mse',\n",
        "              optimizer = optimizer,\n",
        "              metrics=['mae'])"
      ],
      "metadata": {
        "id": "xSW7YJaxJMBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# checkpoint\n",
        "filepath=\"/content/drive/MyDrive/models/saved_model-lr1e-3-3lstm-{epoch:02d}-{val_loss:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss',\n",
        "                             save_weights_only=True,\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')\n",
        "#callbacks_list = [ checkpoint,tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3,) ]\n",
        "callbacks_list = [ checkpoint]\n",
        "\n",
        "history = model.fit(ds_train,\n",
        "                    epochs= EPOCHS,\n",
        "                    validation_data = ds_val,\n",
        "                    steps_per_epoch= TRAIN_STEPS,\n",
        "                    validation_steps = VAL_STEPS,\n",
        "                    callbacks = callbacks_list)"
      ],
      "metadata": {
        "id": "4FV1VvXxJ2FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZC0A6lcgKW4p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}